{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DA_2_2_4.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Module 2: Main Analysis types\n",
        "## Sprint 2: Funnels and A/B Testing\n",
        "## Part 4: Graded Task\n",
        "\n"
      ],
      "metadata": {
        "id": "mg46lK8OEbuU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "You have a follow up task from your marketing manager. She does not trust the A/B test data you calculated previously looking at “NewYear” and “BlackFriday” campaigns and testing if versions had significantly different clickthrough rate (Clicks/Impressions). She thinks that the clicks were not tracked properly and those numbers are wrong, though she trusts that number of impressions are correct.\n",
        "\n",
        "She asks you to come up with an alternative way to estimate how many people actually clicked on those banners from marketing “NewYear” and “BlackFriday” campaigns. You remember that you also have website tracking data in [turing_data_analytics.raw_events table](https://console.cloud.google.com/bigquery?authuser=3&project=tc-da-1&ws=!1m14!1m3!8m2!1s756497109418!2s1b8fa7cb3d73401f81fea1591fa615a7!1m4!4m3!1stc-da-1!2sturing_data_analytics!3sstackoverflow_posts!1m4!4m3!1stc-da-1!2sturing_data_analytics!3sraw_events&d=turing_data_analytics&p=tc-da-1&t=raw_events&page=table) and you decide to estimate the number of users who clicked on marketing campaigns banners from this data, by calculating unique users who had at least one page view. So you join your original data of marketing campaigns from [turing_data_analytics.adsense_monthly](https://console.cloud.google.com/bigquery?authuser=3&project=tc-da-1&ws=!1m19!1m3!8m2!1s756497109418!2s1b8fa7cb3d73401f81fea1591fa615a7!1m4!4m3!1stc-da-1!2sturing_data_analytics!3sstackoverflow_posts!1m4!4m3!1stc-da-1!2sturing_data_analytics!3sraw_events!1m4!4m3!1stc-da-1!2sturing_data_analytics!3sadsense_monthly&d=turing_data_analytics&p=tc-da-1&t=adsense_monthly&page=table) with this table and replace original clicks tracked by adsense data with your new estimate - the number of unique users these marketing campaigns brought to your website.\n",
        "\n",
        "<br>\n",
        "\n",
        "## Task requirements\n",
        "\n",
        "1. You should prepare SQL query which would pull all data needed and similarly as before estimate if different variants of marketing campaigns (V1 vs V2) for both “NewYear” and “BlackFriday” campaigns had significantly better clickthrough rates (estimated as: number of users who clicked on campaign / number of impressions).\n",
        "  - For now you can ignore timing of user tracking data, you do not need to check if those sessions were recorded when the marketing campaign was running.\n",
        "2. Run the A/B testing on the results from your query.\n",
        "  - You can use Binomial A/B test Calculator.\n",
        "  - Bonus points if you create your own/custom A/B testing for this exercise.\n",
        "3. Add visualizations to help illustrate A/B testing results.\n",
        "\n",
        "<br>\n",
        "\n",
        "## Evaluation criteria:\n",
        "\n",
        "- SQL, correct columns identified to make analysis. \n",
        "- Correctly calculated estimate for clickthrough rates. \n",
        "- Correctly performed A/B tests for both marketing campaigns.\n",
        "- Google Sheets data visualizations are included.\n",
        "- Analysis, findings and main points clearly structured.\n",
        "- Analytical approach to the problem\n",
        "\n",
        "<br>\n",
        "\n",
        "During a task review, you may get asked questions that test your understanding of covered topics.\n",
        "\n",
        "**Sample questions**:\n",
        "\n",
        "- What would you have to have in mind running V1 and V2 marketing campaigns in order to be able to use A/B tests for evaluating their performance?\n",
        "- What would be a better metric than Impressions to act as a denominator in click through rate formula?\n",
        "- How would you adjust your query to take into account timing of sessions as well?\n",
        "- Which of the two campaigns had significantly different results? Which version of this marketing campaign had better performance?\n",
        "\n",
        "<br> \n",
        "\n",
        "\n",
        "## Submission\n",
        "Upload solutions for both this and the Funnels graded task to the GitHub repository using the \"Add File\" function. Prepare to present both projects during your correction.\n"
      ],
      "metadata": {
        "id": "adeV8c2MGVZo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<br>\n",
        "\n",
        "## Accessing the next notebook:\n",
        "After you schedule your project reviews, you can already start working on the next part from the upcoming sprint. To access it, go to https://github.com/TuringCollegeSubmissions/DA.2.3.1. If you need access to additional parts of the next sprint, contact Giedrius Zebrauskas via Discord. Once the project review is completed, you will see this content in the Turing platform normally."
      ],
      "metadata": {
        "id": "LlGybqrASuhi"
      }
    }
  ]
}